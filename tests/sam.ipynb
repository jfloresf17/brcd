{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHECK shapes -> S2 CHW: (3, 64, 64) | SR CHW: (3, 256, 256) | SAM HWC: (256, 256, 3)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 146\u001b[39m\n\u001b[32m    144\u001b[39m     test_chunk = np.asarray(build_boxes_sr[:\u001b[32m2\u001b[39m], dtype=np.float32)  \u001b[38;5;66;03m# (n,4)\u001b[39;00m\n\u001b[32m    145\u001b[39m     predictor.set_image(img_uint8_sr)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     _m, _, _ = \u001b[43mpredictor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultimask_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOK SAM test masks shape:\u001b[39m\u001b[33m\"\u001b[39m, _m.shape)  \u001b[38;5;66;03m# esperado: (n, Hsr, Wsr)\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# ---------- 4) Refinado por clase en SR ----------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/miniconda3/envs/tfm/lib/python3.11/site-packages/segment_anything/predictor.py:154\u001b[39m, in \u001b[36mSamPredictor.predict\u001b[39m\u001b[34m(self, point_coords, point_labels, box, mask_input, multimask_output, return_logits)\u001b[39m\n\u001b[32m    151\u001b[39m     mask_input_torch = torch.as_tensor(mask_input, dtype=torch.float, device=\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    152\u001b[39m     mask_input_torch = mask_input_torch[\u001b[38;5;28;01mNone\u001b[39;00m, :, :, :]\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m masks, iou_predictions, low_res_masks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_torch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoords_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbox_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmask_input_torch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmultimask_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m masks_np = masks[\u001b[32m0\u001b[39m].detach().cpu().numpy()\n\u001b[32m    164\u001b[39m iou_predictions_np = iou_predictions[\u001b[32m0\u001b[39m].detach().cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/miniconda3/envs/tfm/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/miniconda3/envs/tfm/lib/python3.11/site-packages/segment_anything/predictor.py:222\u001b[39m, in \u001b[36mSamPredictor.predict_torch\u001b[39m\u001b[34m(self, point_coords, point_labels, boxes, mask_input, multimask_output, return_logits)\u001b[39m\n\u001b[32m    219\u001b[39m     points = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# Embed prompts\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m sparse_embeddings, dense_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprompt_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpoints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Predict masks\u001b[39;00m\n\u001b[32m    229\u001b[39m low_res_masks, iou_predictions = \u001b[38;5;28mself\u001b[39m.model.mask_decoder(\n\u001b[32m    230\u001b[39m     image_embeddings=\u001b[38;5;28mself\u001b[39m.features,\n\u001b[32m    231\u001b[39m     image_pe=\u001b[38;5;28mself\u001b[39m.model.prompt_encoder.get_dense_pe(),\n\u001b[32m   (...)\u001b[39m\u001b[32m    234\u001b[39m     multimask_output=multimask_output,\n\u001b[32m    235\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/miniconda3/envs/tfm/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/miniconda3/envs/tfm/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/miniconda3/envs/tfm/lib/python3.11/site-packages/segment_anything/modeling/prompt_encoder.py:159\u001b[39m, in \u001b[36mPromptEncoder.forward\u001b[39m\u001b[34m(self, points, boxes, masks)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m boxes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    158\u001b[39m     box_embeddings = \u001b[38;5;28mself\u001b[39m._embed_boxes(boxes)\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     sparse_embeddings = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msparse_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox_embeddings\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m masks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    162\u001b[39m     dense_embeddings = \u001b[38;5;28mself\u001b[39m._embed_masks(masks)\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import binary_opening, disk\n",
    "import torch\n",
    "\n",
    "from models.rrdbnet import RRDBNet\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SR_SCALE = 4\n",
    "MIN_AREA = 16\n",
    "BOX_BUFFER = 2\n",
    "BATCH_BOXES = 64\n",
    "MULTIMASK_OUTPUT = False\n",
    "\n",
    "S2_RGB_TIF = \"/home/tidop/masterIA/TFM_BRCD/data/filtered/s2/s2_26318.tif\"\n",
    "BUILD_MASK_TIF = \"/home/tidop/masterIA/TFM_BRCD/data/filtered/building/building_26318.tif\"\n",
    "ROAD_MASK_TIF  = \"/home/tidop/masterIA/TFM_BRCD/data/filtered/road/road_26318.tif\"\n",
    "REAL_ESRGAN_CKPT = \"../checkpoints/checkpoint.tar\"\n",
    "SAM_CKPT = \"../checkpoints/sam_vit_b_01ec64.pth\"\n",
    "\n",
    "# ---------- helpers de forma ----------\n",
    "def chw01_to_hwc_uint8(chw):\n",
    "    \"\"\"(3,H,W)->(H,W,3) uint8 0..255\"\"\"\n",
    "    assert chw.ndim == 3 and chw.shape[0] == 3, f\"Esperaba CHW con C=3, tengo {chw.shape}\"\n",
    "    arr = np.clip(chw, 0, 1)\n",
    "    arr = (arr * 255.0).round().astype(np.uint8)\n",
    "    return np.moveaxis(arr, 0, -1)  # CHW -> HWC\n",
    "\n",
    "def read_s2_rgb_chw01(path):\n",
    "    \"\"\"Lee S2 RGB como float01 CHW (3,H,W). Ajusta los índices a tu orden real.\"\"\"\n",
    "    with rio.open(path) as src:\n",
    "        # si tu archivo ya trae RGB en [3,2,1], usa esos; si tiene 4 bandas RGBN, usa [4,3,2].\n",
    "        if src.count >= 4:\n",
    "            rgb = src.read(indexes=[4,3,2]).astype(np.float32)  # (3,H,W)\n",
    "        else:\n",
    "            rgb = src.read(indexes=[3,2,1]).astype(np.float32)\n",
    "    rgb /= max(1e-6, rgb.max())\n",
    "    assert rgb.ndim == 3 and rgb.shape[0] == 3, f\"RGB esperado como CHW (3,H,W), obtuve {rgb.shape}\"\n",
    "    return rgb  # CHW\n",
    "\n",
    "def read_mask_binary_hw(path):\n",
    "    \"\"\"Lee máscara HW binaria {0,1}.\"\"\"\n",
    "    with rio.open(path) as src:\n",
    "        m = src.read(1)\n",
    "    m = (m > 0).astype(np.uint8)\n",
    "    assert m.ndim == 2, f\"Máscara no es HW, shape={m.shape}\"\n",
    "    return m\n",
    "\n",
    "def component_boxes_xyxy(mask01, buffer_px=2, min_area=16):\n",
    "    \"\"\"\n",
    "    A partir de una máscara HW binaria, obtiene boxes en XYXY (x1,y1,x2,y2)\n",
    "    NOTA: regionprops entrega bbox en (y1, x1, y2, x2); convertimos a XY.\n",
    "    \"\"\"\n",
    "    m = (mask01 > 0).astype(np.uint8)\n",
    "    if m.sum() == 0:\n",
    "        return []\n",
    "    m = binary_opening(m, disk(1)).astype(np.uint8)\n",
    "\n",
    "    lab = label(m, connectivity=1)\n",
    "    H, W = m.shape\n",
    "    boxes = []\n",
    "    for rp in regionprops(lab):\n",
    "        if rp.area < min_area:\n",
    "            continue\n",
    "        y1, x1, y2, x2 = rp.bbox  # (y1, x1, y2, x2) half-open\n",
    "        # cerramos a píxeles + buffer\n",
    "        x1 = max(0, x1 - buffer_px)\n",
    "        y1 = max(0, y1 - buffer_px)\n",
    "        x2 = min(W-1, x2 - 1 + buffer_px)\n",
    "        y2 = min(H-1, y2 - 1 + buffer_px)\n",
    "        boxes.append([float(x1), float(y1), float(x2), float(y2)])  # XYXY\n",
    "    return boxes\n",
    "\n",
    "def upscale_boxes_xyxy(boxes, scale):\n",
    "    if scale == 1 or not boxes:\n",
    "        return boxes\n",
    "    return [[x1*scale, y1*scale, x2*scale, y2*scale] for (x1,y1,x2,y2) in boxes]\n",
    "\n",
    "def run_sam_boxes(predictor, image_uint8, boxes_xyxy, multimask_output=False):\n",
    "    \"\"\"\n",
    "    Procesa UNA caja por llamada (compatible con builds de SAM que no soportan batch de boxes).\n",
    "    - image_uint8: (H,W,3) uint8 en la MISMA grilla que 'boxes_xyxy'\n",
    "    - boxes_xyxy: lista de [x1,y1,x2,y2] (floats)\n",
    "    Devuelve máscara HW binaria (OR de todas las cajas).\n",
    "    \"\"\"\n",
    "    predictor.set_image(image_uint8)\n",
    "    H, W = image_uint8.shape[:2]\n",
    "    out_mask = np.zeros((H, W), dtype=bool)\n",
    "\n",
    "    for b in boxes_xyxy:\n",
    "        box = np.asarray(b, dtype=np.float32).reshape(1, 4)  # (1,4) una sola caja\n",
    "        masks, _, _ = predictor.predict(\n",
    "            box=box, point_coords=None, point_labels=None,\n",
    "            multimask_output=multimask_output\n",
    "        )\n",
    "        # masks: (1,H,W) si multimask_output=False ; (1,M,H,W) si True\n",
    "        m = masks[0] if masks.ndim == 3 else masks.any(axis=1)[0]\n",
    "        out_mask |= m\n",
    "\n",
    "    return out_mask.astype(np.uint8)\n",
    "\n",
    "# ---------- 1) SR en CHW y conversión a HWC ----------\n",
    "# Carga SR\n",
    "net_hr = RRDBNet(num_in_ch=3, num_out_ch=3, scale=SR_SCALE).to(DEVICE)\n",
    "state = torch.load(REAL_ESRGAN_CKPT, map_location=\"cpu\")\n",
    "net_hr.load_state_dict(state['net_g_ema'])\n",
    "net_hr.eval().half()\n",
    "for p in net_hr.parameters(): p.requires_grad = False\n",
    "\n",
    "# S2 como CHW\n",
    "s2_chw = read_s2_rgb_chw01(S2_RGB_TIF)                    # (3,H,W)\n",
    "s2_tensor = torch.from_numpy(s2_chw).unsqueeze(0).to(DEVICE)  # (1,3,H,W)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sr_tensor = net_hr(s2_tensor.half())                  # (1,3,4H,4W)\n",
    "sr_chw = sr_tensor.squeeze(0).float().cpu().numpy().clip(0,1)  # (3,4H,4W)\n",
    "\n",
    "# SAM: HWC uint8\n",
    "img_uint8_sr = chw01_to_hwc_uint8(sr_chw)                 # (4H,4W,3)\n",
    "\n",
    "print(\"CHECK shapes -> S2 CHW:\", s2_chw.shape,\n",
    "      \"| SR CHW:\", sr_chw.shape, \"| SAM HWC:\", img_uint8_sr.shape)\n",
    "\n",
    "# ---------- 2) Máscaras HW y boxes en grilla nativa ----------\n",
    "build_mask = read_mask_binary_hw(BUILD_MASK_TIF)  # (H,W) 256x256\n",
    "road_mask  = read_mask_binary_hw(ROAD_MASK_TIF)   # (H,W) 256x256\n",
    "assert build_mask.shape == road_mask.shape, \"Máscaras con distinta forma\"\n",
    "\n",
    "build_boxes_native = component_boxes_xyxy(build_mask, buffer_px=BOX_BUFFER, min_area=MIN_AREA)\n",
    "road_boxes_native  = component_boxes_xyxy(road_mask,  buffer_px=BOX_BUFFER, min_area=MIN_AREA)\n",
    "\n",
    "# como pasamos a SAM la SR (4H,4W), escalamos cajas ×4\n",
    "build_boxes_sr = upscale_boxes_xyxy(build_boxes_native, SR_SCALE)\n",
    "road_boxes_sr  = upscale_boxes_xyxy(road_boxes_native,  SR_SCALE)\n",
    "\n",
    "# ---------- 3) SAM ----------\n",
    "sam = sam_model_registry[\"vit_b\"](checkpoint=SAM_CKPT).to(DEVICE)\n",
    "predictor = SamPredictor(sam)\n",
    "\n",
    "# Smoke test (opcional): 1–2 cajas para validar shapes\n",
    "if len(build_boxes_sr) > 0:\n",
    "    test_chunk = np.asarray(build_boxes_sr[:2], dtype=np.float32)  # (n,4)\n",
    "    predictor.set_image(img_uint8_sr)\n",
    "    _m, _, _ = predictor.predict(box=test_chunk, multimask_output=False)\n",
    "    print(\"OK SAM test masks shape:\", _m.shape)  # esperado: (n, Hsr, Wsr)\n",
    "\n",
    "# ---------- 4) Refinado por clase en SR ----------\n",
    "build_ref_sr = run_sam_boxes(predictor, img_uint8_sr, build_boxes_sr,\n",
    "                             batch=BATCH_BOXES, multimask_output=MULTIMASK_OUTPUT)\n",
    "road_ref_sr  = run_sam_boxes(predictor, img_uint8_sr, road_boxes_sr,\n",
    "                             batch=BATCH_BOXES, multimask_output=MULTIMASK_OUTPUT)\n",
    "\n",
    "# ---------- 5) Bajar a 256x256 y componer semántica ----------\n",
    "from skimage.transform import resize\n",
    "\n",
    "def down_nn(mask_hw, out_hw):\n",
    "    return (resize(mask_hw.astype(float), out_hw, order=0, preserve_range=True) > 0.5).astype(np.uint8)\n",
    "\n",
    "build_ref_native = down_nn(build_ref_sr, build_mask.shape)\n",
    "road_ref_native  = down_nn(road_ref_sr,  road_mask.shape)\n",
    "\n",
    "final_sem = np.zeros_like(build_mask, dtype=np.uint8)\n",
    "final_sem[build_ref_native == 1] = 1\n",
    "final_sem[(final_sem == 0) & (road_ref_native == 1)] = 2\n",
    "\n",
    "print(\"FINAL shapes -> build_ref_sr:\", build_ref_sr.shape,\n",
    "      \"| final_sem (nativo):\", final_sem.shape)  # debería ser (256,256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
